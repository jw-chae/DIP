{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is final codeworks and comparing<br>\n",
    "detector used KAZE, ORB and SIFT<BR>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "img1 = cv2.imread('./images/images/img_main.jpg')          # queryImage\n",
    "img1 = cv2.resize(img1,(500,300))\n",
    "img2 = cv2.imread('./images/images/img1.png') # trainImage\n",
    "\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./images/images/img1.png',\n",
       " './images/images/img2.png',\n",
       " './images/images/img3.png',\n",
       " './images/images/img4.png',\n",
       " './images/images/img5.png',\n",
       " './images/images/img6.png',\n",
       " './images/images/img7.png',\n",
       " './images/images/img8.png',\n",
       " './images/images/img9.png',\n",
       " './images/images/img10.png',\n",
       " './images/images/img11.png',\n",
       " './images/images/img12.png',\n",
       " './images/images/img13.png']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list=[]\n",
    "for i in range(1,14):\n",
    "    globals() [i]= './images/images/img{}.png'.format(i) \n",
    "    img_list.append(globals()[i])\n",
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detect_ORB(img1,img2):\n",
    "\n",
    "    # 특징점 알고리즘 객체 생성 (KAZE, AKAZE, ORB 등)\n",
    "    detector = cv2.ORB_create() # 기본값인 L2놈 이용\n",
    "    #feature = cv2.AKAZE_create()\n",
    "    #feature = cv2.ORB_create()\n",
    "\n",
    "    # 특징점 검출 및 기술자 계산\n",
    "    kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "    kp2, desc2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # 특징점 매칭\n",
    "    matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = matcher.match(desc1, desc2)\n",
    "\n",
    "    # 좋은 매칭 결과 선별\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    good_matches = matches[:20]\n",
    "\n",
    "    print('# of kp1:', len(kp1))\n",
    "    print('# of kp2:', len(kp2))\n",
    "    print('# of matches:', len(matches))\n",
    "    print('# of good_matches:', len(good_matches))\n",
    "\n",
    "    # 호모그래피 계산\n",
    "    # DMatch 객체에서 queryIdx와 trainIdx를 받아와서 크기와 타입 변환하기\n",
    "    pts1 = np.array([kp1[m.queryIdx].pt for m in good_matches]\n",
    "                    ).reshape(-1, 1, 2).astype(np.float32)\n",
    "    pts2 = np.array([kp2[m.trainIdx].pt for m in good_matches]\n",
    "                    ).reshape(-1, 1, 2).astype(np.float32)\n",
    "                    \n",
    "    H, _ = cv2.findHomography(pts1, pts2, cv2.RANSAC,5.0) # pts1과 pts2의 행렬 주의 (N,1,2)\n",
    "\n",
    "    # 호모그래피를 이용하여 기준 영상 영역 표시\n",
    "    dst = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None,\n",
    "                        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    (h, w) = img1.shape[:2]\n",
    "\n",
    "    # 입력 영상의 모서리 4점 좌표\n",
    "    corners1 = np.array([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]\n",
    "                        ).reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # 입력 영상에 호모그래피 H 행렬로 투시 변환\n",
    "    corners2 = cv2.perspectiveTransform(corners1, H)\n",
    "\n",
    "    # corners2는 입력 영상에 좌표가 표현되있으므로 입력영상의 넓이 만큼 쉬프트\n",
    "    corners2 = corners2 + np.float32([w, 0])\n",
    "\n",
    "    # 다각형 그리기\n",
    "    cv2.polylines(dst, [np.int32(corners2)], True, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 500\n",
      "# of good_matches: 20\n"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    object_detect_ORB(img1,cv2.imread(img_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detect_SIFT(img1,img2):\n",
    "\n",
    "    # 특징점 알고리즘 객체 생성 (KAZE, AKAZE, ORB 등)\n",
    "    detector = cv2.ORB_create() # 기본값인 L2놈 이용\n",
    "    #feature = cv2.AKAZE_create()\n",
    "    #feature = cv2.ORB_create()\n",
    "\n",
    "    # 특징점 검출 및 기술자 계산\n",
    "    kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "    kp2, desc2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # 특징점 매칭\n",
    "    matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = matcher.match(desc1, desc2)\n",
    "\n",
    "    # 좋은 매칭 결과 선별\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    good_matches = matches[:20]\n",
    "\n",
    "    print('# of kp1:', len(kp1))\n",
    "    print('# of kp2:', len(kp2))\n",
    "    print('# of matches:', len(matches))\n",
    "    print('# of good_matches:', len(good_matches))\n",
    "\n",
    "    # 호모그래피 계산\n",
    "    # DMatch 객체에서 queryIdx와 trainIdx를 받아와서 크기와 타입 변환하기\n",
    "    pts1 = np.array([kp1[m.queryIdx].pt for m in good_matches]\n",
    "                    ).reshape(-1, 1, 2).astype(np.float32)\n",
    "    pts2 = np.array([kp2[m.trainIdx].pt for m in good_matches]\n",
    "                    ).reshape(-1, 1, 2).astype(np.float32)\n",
    "                    \n",
    "    H, _ = cv2.findHomography(pts1, pts2, cv2.RANSAC) # pts1과 pts2의 행렬 주의 (N,1,2)\n",
    "\n",
    "    # 호모그래피를 이용하여 기준 영상 영역 표시\n",
    "    dst = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None,\n",
    "                        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    (h, w) = img1.shape[:2]\n",
    "\n",
    "    # 입력 영상의 모서리 4점 좌표\n",
    "    corners1 = np.array([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]\n",
    "                        ).reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # 입력 영상에 호모그래피 H 행렬로 투시 변환\n",
    "    corners2 = cv2.perspectiveTransform(corners1, H)\n",
    "\n",
    "    # corners2는 입력 영상에 좌표가 표현되있으므로 입력영상의 넓이 만큼 쉬프트\n",
    "    corners2 = corners2 + np.float32([w, 0])\n",
    "\n",
    "    # 다각형 그리기\n",
    "    cv2.polylines(dst, [np.int32(corners2)], True, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 139\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 139\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 153\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 148\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 140\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 136\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 130\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 137\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 149\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 153\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 153\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 150\n",
      "# of good_matches: 20\n",
      "# of kp1: 500\n",
      "# of kp2: 500\n",
      "# of matches: 140\n",
      "# of good_matches: 20\n"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    object_detect_SIFT(img1,cv2.imread(img_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detect_KAZE(img1,img2):\n",
    "\n",
    "    # 특징점 알고리즘 객체 생성 (KAZE, AKAZE, ORB 등)\n",
    "    detector = cv2.KAZE_create() # 기본값인 L2놈 이용\n",
    "    #feature = cv2.AKAZE_create()\n",
    "    #feature = cv2.ORB_create()\n",
    "\n",
    "    # 특징점 검출 및 기술자 계산\n",
    "    kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "    kp2, desc2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "    # 특징점 매칭\n",
    "    matcher = cv2.BFMatcher_create()\n",
    "    matches = matcher.match(desc1, desc2)\n",
    "\n",
    "    # 좋은 매칭 결과 선별\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    good_matches = matches[:20]\n",
    "\n",
    "    print('# of kp1:', len(kp1))\n",
    "    print('# of kp2:', len(kp2))\n",
    "    print('# of matches:', len(matches))\n",
    "    print('# of good_matches:', len(good_matches))\n",
    "\n",
    "    # 호모그래피 계산\n",
    "    # DMatch 객체에서 queryIdx와 trainIdx를 받아와서 크기와 타입 변환하기\n",
    "    pts1 = np.array([kp1[m.queryIdx].pt for m in good_matches]\n",
    "                    ).reshape(-1, 1, 2).astype(np.float32)\n",
    "    pts2 = np.array([kp2[m.trainIdx].pt for m in good_matches]\n",
    "                    ).reshape(-1, 1, 2).astype(np.float32)\n",
    "                    \n",
    "    H, _ = cv2.findHomography(pts1, pts2, cv2.RANSAC) # pts1과 pts2의 행렬 주의 (N,1,2)\n",
    "\n",
    "    # 호모그래피를 이용하여 기준 영상 영역 표시\n",
    "    dst = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None,\n",
    "                        flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    (h, w) = img1.shape[:2]\n",
    "\n",
    "    # 입력 영상의 모서리 4점 좌표\n",
    "    corners1 = np.array([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]\n",
    "                        ).reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "    # 입력 영상에 호모그래피 H 행렬로 투시 변환\n",
    "    corners2 = cv2.perspectiveTransform(corners1, H)\n",
    "\n",
    "    # corners2는 입력 영상에 좌표가 표현되있으므로 입력영상의 넓이 만큼 쉬프트\n",
    "    corners2 = corners2 + np.float32([w, 0])\n",
    "\n",
    "    # 다각형 그리기\n",
    "    cv2.polylines(dst, [np.int32(corners2)], True, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    object_detect_KAZE(img1,cv2.imread(img_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Initiate SIFT detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# find the keypoints and descriptors with ORB\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "\n",
    "# create BFMatcher object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptors.\n",
    "matches = bf.match(des1,des2)\n",
    "\n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "good_matches = matches[:10]\n",
    "\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches     ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "matchesMask = mask.ravel().tolist()\n",
    "h,w = img1.shape[:2]\n",
    "pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "\n",
    "dst = cv2.perspectiveTransform(pts,M)\n",
    "dst += (w, 0)  # adding offset\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08511fb726953861695b9cebc649e5cfa50177e02ef8da1c1316f73897c02d54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
